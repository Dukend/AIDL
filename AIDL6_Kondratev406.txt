Кондратьев Егор 406
Статья 1:"Learning to learn by gradient descent by gradient descent" by Marcin Andrychowicz
https://arxiv.org/abs/1606.04474
В этой статье задача обучения оптимизации представлена как проблема мета-обучения. Авторы предлагают подход мета-обучения под названием "Обучение обучению путем градиентного спуска по градиенту" (L2L-GD), который предполагает обучение нейронной сети для оптимизации функции потерь с помощью градиентного спуска, чтобы затем оптимизированную модель можно было использовать для оптимизации других моделей.

Подход L2L-GD предполагает двухуровневый процесс обучения, где внешний цикл включает оптимизацию мета-модели (которая учится оптимизировать другие модели), а внутренний цикл - оптимизацию обучаемых моделей (с использованием мета-модели). Авторы используют комбинацию обратного распространения и мета-целевой функции для обучения мета-модели, что позволяет ей учиться обобщать новые задачи и модели.

В целом, подход L2L-GD является примером метаобучения на основе моделей, когда метамодель обучается для изучения модели процесса оптимизации, которая затем может быть использована для оптимизации других моделей.

Статья 2: "Meta-learning with differentiable closed-form solvers" by Chelsea Finn
https://arxiv.org/abs/1805.08136
В этой статье задача обучения новой задаче на небольшом количестве примеров представлена как проблема метаобучения. Авторы предлагают подход к метаобучению под названием "Метаобучение с дифференцируемыми замкнутыми формами решений" (MAML-DCFS), который предполагает обучение нейронной сети быстрой адаптации к новым задачам путем изучения набора дифференцируемых замкнутых форм решений.

Подход MAML-DCFS предполагает двухуровневый процесс обучения, где внешний цикл включает оптимизацию мета-модели (которая обучается дифференцируемым решениям в замкнутой форме), а внутренний цикл - адаптацию мета-модели к новым задачам (путем обновления весов с помощью градиентного спуска). Авторы используют комбинацию обратного распространения и мета-целевой функции для обучения мета-модели, что позволяет ей быстро адаптироваться к новым задачам на небольшом количестве примеров.

В целом, подход MAML-DCFS является примером подхода метаобучения, не зависящего от модели, когда метамодель обучается набору дифференцируемых решений в замкнутой форме, которые могут быть применены к любой модели или задаче. Этот подход особенно полезен при обучении с небольшим количеством примеров, когда целью является быстрая адаптация к новым задачам на небольшом количестве примеров.